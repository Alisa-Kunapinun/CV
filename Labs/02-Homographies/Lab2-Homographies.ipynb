{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 Homographies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUI programing in OpenCV\n",
    "\n",
    "The methods of showing images in openCV are in <code>highgui.hpp</code>. The important methods are:\n",
    " - <code>imshow()</code>: show an image in a window. If there is the window which has the same name to show, the image will replace the old image in the same window.\n",
    " - <code>waitKey()</code>: wait a key input until time up or until the key is pressed.\n",
    " - <code>destroyWindow()</code>: destroy a target window\n",
    " - <code>destroyAllWindows()</code>: destroy all windows in the program\n",
    " \n",
    "Let's start with a simple version of our solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tip before start\n",
    "**For Visual Studio in Window users in C++**: If you want to open files by using only filename (does not include path of the file), you must put the files such as image file or video file at the same path which cpp file (which has main function) stored.\n",
    "\n",
    "For example: I created a project name Samplelab2 in default drive <code>C:\\Users\\alisa\\source\\repos</code>. The cpp file which contain main function is in path <code>C:\\Users\\alisa\\source\\repos\\Samplelab2\\Samplelab2</code>, so I put the image file named \"lena.png\" at the path as below:\n",
    "\n",
    "<img src=\"img/lab02-1.PNG\" width=\"800\"/>\n",
    "\n",
    "After that, you can use the file without add the folder path.\n",
    "\n",
    "<code>Mat srcImage = imread(\"lenna.png\");</code>\n",
    "\n",
    "However, if you open the execute file outside visual studio, you must put the files at the same path as execution file.\n",
    "\n",
    "**In python**, you can do the same as above.\n",
    "\n",
    "**For Linux users**: The image file must put at the same as build file path (.o file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <opencv2/opencv.hpp> // you can use the include library for call \"all\" functions in opencv\n",
    "#include <iostream>\n",
    "\n",
    "using namespace cv;  // You can use any function in cv class by not typing cv::\n",
    "using namespace std; // You can use any function in std class by not typing std::\n",
    "\n",
    "int main( int argc, char** argv )\n",
    "{\n",
    "    cout << \"Show image\" << endl;\n",
    "    \n",
    "    int key = -1;\n",
    "    string img = \"lenna.png\";   // set the image file as string variable\n",
    "    Mat srcImage = imread(img); // read an image from file\n",
    "    if (!srcImage.data) {\n",
    "        cout << \"No image to show\" << endl;\n",
    "        return 1;\n",
    "    }\n",
    "    imshow(\"srcImage\", srcImage);  // Show the image in window named \"srcImage\"\n",
    "    \n",
    "    // wait a key up to 5000 millisecond, it will continue to next step and the key variable will get -1\n",
    "    // If you press any key before 5000 millisecond, it will return the key variable as ASCII code of the key and continue to next step\n",
    "    // If use waitKey(0), the program will wait forever until a user press any key.\n",
    "    key = waitKey(5000);\n",
    "    cout << \"Key output value: \" << char(key) << endl;\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "VIDEO_FILE = \"robot.mp4\"   # define VIDEO_FILE as string, the value is \"robot.mp4\"\n",
    "ROTATE = False             # define ROTATE as boolean, the value is true\n",
    "\n",
    "def main():\n",
    "    # set the image file as string variable\n",
    "    path = r'lefna.png'\n",
    "  \n",
    "    # read an image from file\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        print(\"No image to show\")\n",
    "        return -1\n",
    "  \n",
    "    # Show the image in window named \"srcImage\"\n",
    "    cv2.imshow('image', img)\n",
    "    # wait a key up to 5000 millisecond, it will continue to next step and the key variable will get -1\n",
    "    # If you press any key before 5000 millisecond, it will return the key variable as ASCII code of the key and continue to next step\n",
    "    # If use waitKey(0), the program will wait forever until a user press any key.\n",
    "    cv2.waitKey(5000);\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show an video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <opencv2/opencv.hpp> // you can use the include library for call \"all\" functions in opencv\n",
    "#include <iostream>\n",
    "\n",
    "using namespace cv;  // You can use any function in cv class by not typing cv::\n",
    "using namespace std; // You can use any function in std class by not typing std::\n",
    "\n",
    "// In C++, you can define a constant variable by using #define\n",
    "#define VIDEO_FILE \"robot.mp4\"   // define VIDEO_FILE as string, the value is \"robot.mp4\"\n",
    "#define ROTATE false              // define ROTATE as boolean, the value is true\n",
    "\n",
    "int main(int argc, char** argv)\n",
    "{\n",
    "    Mat matFrameCapture;\n",
    "    Mat matFrameDisplay;\n",
    "    int key = -1;\n",
    "\n",
    "    // Open input video file\n",
    "    VideoCapture videoCapture(VIDEO_FILE);\n",
    "    if (!videoCapture.isOpened()) {\n",
    "        cerr << \"ERROR! Unable to open input video file \" << VIDEO_FILE << endl;\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    // Capture loop\n",
    "    while (key != int(' '))        // play video until press 'spacebar'\n",
    "    {\n",
    "        // Get the next frame\n",
    "        videoCapture.read(matFrameCapture);\n",
    "        if (matFrameCapture.empty()) {   // no more frame capture from the video\n",
    "            // End of video file\n",
    "            break;\n",
    "        }\n",
    "\n",
    "        // Rotate if needed, some video has output like top go down, so we need to rotate it\n",
    "#if ROTATE\n",
    "        rotate(matFrameCapture, matFrameDisplay, RotateFlags::ROTATE_180);   //rotate 180 degree and put the image to matFrameDisplay\n",
    "#else\n",
    "        matFrameDisplay = matFrameCapture;\n",
    "#endif\n",
    "\n",
    "        float ratio = 640.0 / matFrameDisplay.cols;\n",
    "        resize(matFrameDisplay, matFrameDisplay, cv::Size(), ratio, ratio, INTER_LINEAR); // resize image to 480 * 640 for showing\n",
    "\n",
    "        // Display\n",
    "        imshow(VIDEO_FILE, matFrameDisplay); // Show the image in window named \"robot.mp4\"\n",
    "        key = waitKey(30);\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "VIDEO_FILE = \"robot.mp4\"   # define VIDEO_FILE as string, the value is \"robot.mp4\"\n",
    "ROTATE = False             # define ROTATE as boolean, the value is true\n",
    "\n",
    "def main():\n",
    "    key = -1;\n",
    "\n",
    "    # Open input video file\n",
    "    videoCapture = cv2.VideoCapture(VIDEO_FILE);\n",
    "    if not videoCapture.isOpened():\n",
    "        print(\"ERROR! Unable to open input video file \", VIDEO_FILE)\n",
    "        return -1\n",
    "\n",
    "    width  = videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`\n",
    "    height = videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
    "\n",
    "    # Capture loop \n",
    "    while (key != ord(' ')):        # play video until press 'spacebar'\n",
    "        # Get the next frame\n",
    "        _, matFrameCapture = videoCapture.read()\n",
    "        if matFrameCapture is None:   # no more frame capture from the video\n",
    "            # End of video file\n",
    "            break\n",
    "\n",
    "        # Rotate if needed, some video has output like top go down, so we need to rotate it\n",
    "        if ROTATE:\n",
    "            _, matFrameDisplay = cv2.rotate(matFrameCapture, cv2.ROTATE_180)   #rotate 180 degree and put the image to matFrameDisplay\n",
    "        else:\n",
    "            matFrameDisplay = matFrameCapture;\n",
    "\n",
    "        ratio = 640.0 / width\n",
    "        dim = (int(width * ratio), int(height * ratio))\n",
    "        # resize image to 480 * 640 for showing\n",
    "        matFrameDisplay = cv2.resize(matFrameDisplay, dim)\n",
    "\n",
    "        # Show the image in window named \"robot.mp4\"\n",
    "        cv2.imshow(VIDEO_FILE, matFrameDisplay)\n",
    "        key = cv2.waitKey(30)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get <code>waitKey()</code> to wait for the user to press <space> to advance to the next frame or 'q' to quit. Check the <link>[documentation for waitKey()](https://docs.opencv.org/4.3.0/d7/dfc/group__highgui.html#ga5628525ad33f52eab17feebcfba38bd7)</link>, change the delay parameter to 0 for an infinite wait, and perform the necessary action on a 'spacebar' or 'q' key.\n",
    "\n",
    "The next thing we'd want to do is make sure the image window size is within the user's desktop display size. Currently, the display window is probably too big for your desktop. Take a look at the <link>[documentation for namedWindow()](https://docs.opencv.org/4.3.0/d7/dfc/group__highgui.html#ga5afdf8410934fd099df85c75b2e0888b)</link> and figure out which flags you should use to set up your display window to be resizable but keep the aspect ratio and display the expanded GUI.\n",
    "\n",
    "Next we probably want to give the user some useful information. Check out the <link>[documentation for displayOverlay()](https://docs.opencv.org/4.3.0/dc/d46/group__highgui__qt.html#ga704e0387318cd1e7928e6fe17e81d6aa)</link> and add some explanatory information for the user about frame number, total frames, and user control actions.\n",
    "\n",
    "Last little detail: currently, if the user closes the window, the program doesn't exit. Modify your program to exit when image display window is closed. Hint: try <code>cv::getWindowProperty(VIDEO_FILE, cv::WND_PROP_VISIBLE)</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting four points for a homography\n",
    "\n",
    "Now, we'd like to allow the user to select four points comprising a square in the real world then compute a rectifying homography for that square, thus rectifying the entire ground plane from the robot's point of view.\n",
    "\n",
    "Check out the <link>[documentation for setMouseCallback()](https://docs.opencv.org/4.3.0/d7/dfc/group__highgui.html#ga89e7806b0a616f6f1d502bd8c183ad3e)</link>. Experiment with it until you can get four mouse clicks without interfering with the other GUI functions such as pan/tilt/zoom. Check that you are getting the image coordinates rather than the window coordinates of the mouse clicks.\n",
    "\n",
    "The steps of getting 4 points for homography are:\n",
    " 1. Do the video captures loop\n",
    " 2. press any key to pause the screen and show a new pop-up for showing the pausing image\n",
    " 3. Use the mouse click 4 points.\n",
    " \n",
    "The example code is as below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import library and define some global variables\n",
    "\n",
    "In this step, define a mouseHandler function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <opencv2/opencv.hpp> // you can use the include library for call \"all\" functions in opencv\n",
    "#include <iostream>\n",
    "\n",
    "using namespace cv;  // You can use any function in cv class by not typing cv::\n",
    "using namespace std; // You can use any function in std class by not typing std::\n",
    "\n",
    "// In C++, you can define a constant variable by using #define\n",
    "#define VIDEO_FILE \"robot.mp4\"   // define VIDEO_FILE as string, the value is \"robot.mp4\"\n",
    "#define ROTATE false              // define ROTATE as boolean, the value is true\n",
    "\n",
    "// Create gloabal variables for transfer data to mouse event \n",
    "Mat matPauseScreen, matResult, matFinal;\n",
    "Point point;\n",
    "vector<Point> pts;\n",
    "int var = 0;\n",
    "int drag = 0;\n",
    "\n",
    "// Create mouse handler function\n",
    "void mouseHandler(int, int, int, int, void*);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "VIDEO_FILE = \"robot.mp4\"   # define VIDEO_FILE as string, the value is \"robot.mp4\"\n",
    "ROTATE = False             # define ROTATE as boolean, the value is true\n",
    "\n",
    "matResult = None\n",
    "matFinal = None\n",
    "matPauseScreen = None\n",
    "\n",
    "point = (-1, -1)\n",
    "pts = []\n",
    "var = 0 \n",
    "drag = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a mouse handler function when the mouse event is called"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Mouse handler function has 5 parameters input (no matter what)\n",
    "void mouseHandler(int event, int x, int y, int, void*)\n",
    "{\n",
    "    if (var >= 4) //if homography points are more than 4 points, do nothing\n",
    "        return;\n",
    "    if (event == EVENT_LBUTTONDOWN) // When Press mouse left down\n",
    "    {\n",
    "        drag = 1; // Set it that the mouse is in pressing down mode\n",
    "        matResult = matFinal.clone(); // copy final image to draw image\n",
    "        point = Point(x, y); // memorize current mouse position to point var\n",
    "        if (var >= 1) // if the point has been added more than 1 points, draw a line\n",
    "        {\n",
    "            line(matResult, pts[var - 1], point, Scalar(0, 255, 0, 255), 2); // draw a green line with thickness 2\n",
    "        }\n",
    "        circle(matResult, point, 2, Scalar(0, 255, 0), -1, 8, 0); // draw a current green point\n",
    "        imshow(\"Source\", matResult); // show the current drawing\n",
    "    }\n",
    "    if (event == EVENT_LBUTTONUP && drag) // When Press mouse left up\n",
    "    {\n",
    "        drag = 0; // no more mouse drag\n",
    "        pts.push_back(point);  // add the current point to pts\n",
    "        var++; // increase point number\n",
    "        matFinal = matResult.clone(); // copy the current drawing image to final image\n",
    "        if (var >= 4) // if the homograpy points are done\n",
    "        {\n",
    "            line(matFinal, pts[0], pts[3], Scalar(0, 255, 0, 255), 2); // draw the last line\n",
    "            fillPoly(matFinal, pts, Scalar(0, 120, 0, 20), 8, 0); // draw polygon from points\n",
    "            \n",
    "            setMouseCallback(\"Source\", NULL, NULL); // remove mouse event handler\n",
    "        }\n",
    "        imshow(\"Source\", matFinal);\n",
    "    }\n",
    "    if (drag) // if the mouse is dragging\n",
    "    {\n",
    "        matResult = matFinal.clone(); // copy final images to draw image\n",
    "        point = Point(x, y); // memorize current mouse position to point var\n",
    "        if (var >= 1) // if the point has been added more than 1 points, draw a line\n",
    "        {\n",
    "            line(matResult, pts[var - 1], point, Scalar(0, 255, 0, 255), 2); // draw a green line with thickness 2\n",
    "        }\n",
    "        circle(matResult, point, 2, Scalar(0, 255, 0), -1, 8, 0); // draw a current green point\n",
    "        imshow(\"Source\", matResult); // show the current drawing\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mouse handler function has 5 parameters input (no matter what)\n",
    "def mouseHandler(event, x, y, flags, param):\n",
    "    global point, pts, var, drag, matFinal, matResult   # call global variable to use in this function\n",
    "\n",
    "    if (var >= 4):                           # if homography points are more than 4 points, do nothing\n",
    "        return\n",
    "    if (event == cv2.EVENT_LBUTTONDOWN):     # When Press mouse left down\n",
    "        drag = 1                             # Set it that the mouse is in pressing down mode\n",
    "        matResult = matFinal.copy()          # copy final image to draw image\n",
    "        point = (x, y)                       # memorize current mouse position to point var\n",
    "        if (var >= 1):                       # if the point has been added more than 1 points, draw a line\n",
    "            cv2.line(matResult, pts[var - 1], point, (0, 255, 0, 255), 2)    # draw a green line with thickness 2\n",
    "        cv2.circle(matResult, point, 2, (0, 255, 0), -1, 8, 0)             # draw a current green point\n",
    "        cv2.imshow(\"Source\", matResult)      # show the current drawing\n",
    "    if (event == cv2.EVENT_LBUTTONUP and drag):  # When Press mouse left up\n",
    "        drag = 0                             # no more mouse drag\n",
    "        pts.append(point)                    # add the current point to pts\n",
    "        var += 1                             # increase point number\n",
    "        matFinal = matResult.copy()          # copy the current drawing image to final image\n",
    "        if (var >= 4):                                                      # if the homograpy points are done\n",
    "            cv2.line(matFinal, pts[0], pts[3], (0, 255, 0, 255), 2)   # draw the last line\n",
    "            cv2.fillConvexPoly(matFinal, np.array(pts, 'int32'), (0, 120, 0, 20))        # draw polygon from points\n",
    "        cv2.imshow(\"Source\", matFinal);\n",
    "    if (drag):                                    # if the mouse is dragging\n",
    "        matResult = matFinal.copy()               # copy final images to draw image\n",
    "        point = (x, y)                   # memorize current mouse position to point var\n",
    "        if (var >= 1):                            # if the point has been added more than 1 points, draw a line\n",
    "            cv2.line(matResult, pts[var - 1], point, (0, 255, 0, 255), 2)    # draw a green line with thickness 2\n",
    "        cv2.circle(matResult, point, 2, (0, 255, 0), -1, 8, 0)         # draw a current green point\n",
    "        cv2.imshow(\"Source\", matResult)           # show the current drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the main function for run video and setup mouse hander in window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int main(int argc, char** argv)\n",
    "{\n",
    "    Mat matFrameCapture;\n",
    "    Mat matFrameDisplay;\n",
    "    int key = -1;\n",
    "\n",
    "    // --------------------- [STEP 1: Make video capture from file] ---------------------\n",
    "    // Open input video file\n",
    "    VideoCapture videoCapture(VIDEO_FILE);\n",
    "    if (!videoCapture.isOpened()) {\n",
    "        cerr << \"ERROR! Unable to open input video file \" << VIDEO_FILE << endl;\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    // Capture loop\n",
    "    while (key < 0)        // play video until press any key\n",
    "    {\n",
    "        // Get the next frame\n",
    "        videoCapture.read(matFrameCapture);\n",
    "        if (matFrameCapture.empty()) {   // no more frame capture from the video\n",
    "            // End of video file\n",
    "            break;\n",
    "        }\n",
    "        cvtColor(matFrameCapture, matFrameCapture, COLOR_BGR2BGRA);\n",
    "\n",
    "        // Rotate if needed, some video has output like top go down, so we need to rotate it\n",
    "#if ROTATE\n",
    "        rotate(matFrameCapture, matFrameCapture, RotateFlags::ROTATE_180);   //rotate 180 degree and put the image to matFrameDisplay\n",
    "#endif\n",
    "\n",
    "        float ratio = 640.0 / matFrameCapture.cols;\n",
    "        resize(matFrameCapture, matFrameDisplay, cv::Size(), ratio, ratio, INTER_LINEAR);\n",
    "\n",
    "        // Display\n",
    "        imshow(VIDEO_FILE, matFrameDisplay); // Show the image in window named \"robot.mp4\"\n",
    "        key = waitKey(30);\n",
    "        \n",
    "        // --------------------- [STEP 2: pause the screen and show an image] ---------------------\n",
    "        if (key >= 0)\n",
    "        {\n",
    "            matPauseScreen = matFrameCapture;  // transfer the current image to process\n",
    "            matFinal = matPauseScreen.clone(); // clone image to final image\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // --------------------- [STEP 3: use mouse handler to select 4 points] ---------------------\n",
    "    if (!matFrameCapture.empty())\n",
    "    {\n",
    "        var = 0;   // reset number of saving points\n",
    "        pts.clear(); // reset all points\n",
    "        namedWindow(\"Source\", WINDOW_AUTOSIZE);  // create a windown named source\n",
    "        setMouseCallback(\"Source\", mouseHandler, NULL); // set mouse event handler \"mouseHandler\" at Window \"Source\"\n",
    "        imshow(\"Source\", matPauseScreen); // Show the image\n",
    "        waitKey(0); // wait until press anykey\n",
    "        destroyWindow(\"Source\"); // destroy the window\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        cout << \"You did not pause the screen before the video finish, the program will stop\" << endl;\n",
    "        return 0;\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global matFinal, matResult, matPauseScreen         # call global variable to use in this function\n",
    "    key = -1;\n",
    "\n",
    "    # --------------------- [STEP 1: Make video capture from file] ---------------------\n",
    "    # Open input video file\n",
    "    videoCapture = cv2.VideoCapture(VIDEO_FILE);\n",
    "    if not videoCapture.isOpened():\n",
    "        print(\"ERROR! Unable to open input video file \", VIDEO_FILE)\n",
    "        return -1\n",
    "\n",
    "    width  = videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`\n",
    "    height = videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
    "\n",
    "    # Capture loop \n",
    "    while (key < 0):        # play video until press any key\n",
    "        # Get the next frame\n",
    "        _, matFrameCapture = videoCapture.read()\n",
    "        if matFrameCapture is None:   # no more frame capture from the video\n",
    "            # End of video file\n",
    "            break\n",
    "\n",
    "        # Rotate if needed, some video has output like top go down, so we need to rotate it\n",
    "        if ROTATE:\n",
    "            _, matFrameDisplay = cv2.rotate(matFrameCapture, cv2.ROTATE_180)   #rotate 180 degree and put the image to matFrameDisplay\n",
    "        else:\n",
    "            matFrameDisplay = matFrameCapture;\n",
    "\n",
    "        ratio = 640.0 / width\n",
    "        dim = (int(width * ratio), int(height * ratio))\n",
    "        # resize image to 480 * 640 for showing\n",
    "        matFrameDisplay = cv2.resize(matFrameDisplay, dim)\n",
    "\n",
    "        # Show the image in window named \"robot.mp4\"\n",
    "        cv2.imshow(VIDEO_FILE, matFrameDisplay)\n",
    "        key = cv2.waitKey(30)\n",
    "\n",
    "        # --------------------- [STEP 2: pause the screen and show an image] ---------------------\n",
    "        if (key >= 0):\n",
    "            matPauseScreen = matFrameCapture     # transfer the current image to process\n",
    "            matFinal = matPauseScreen.copy()     # copy image to final image\n",
    "\n",
    "    # --------------------- [STEP 3: use mouse handler to select 4 points] ---------------------\n",
    "    if (matFrameCapture is not None):\n",
    "        var = 0                                             # reset number of saving points\n",
    "        pts.clear()                                         # reset all points\n",
    "        cv2.namedWindow(\"Source\", cv2.WINDOW_AUTOSIZE)      # create a windown named source\n",
    "        cv2.setMouseCallback(\"Source\", mouseHandler)        # set mouse event handler \"mouseHandler\" at Window \"Source\"\n",
    "        cv2.imshow(\"Source\", matPauseScreen)                # Show the image\n",
    "        cv2.waitKey(0)                                      # wait until press anykey\n",
    "        cv2.destroyWindow(\"Source\")                         # destroy the window\n",
    "    else:\n",
    "        print(\"You did not pause the screen before the video finish, the program will stop\")\n",
    "        return 0\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The result should be like this\n",
    "\n",
    "<img src=\"img/lab02-2.PNG\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Homography\n",
    "\n",
    "Now, given the four points that you've collected from the user, calculate a homography to a rectified square with a desired number of pixels per meter, e.g., 1000. The tiles in the video from last week are 60cm x 60cm.\n",
    "\n",
    "Note that OpenCV doesn't have a <code>null()</code> function like Matlab and Octave. Instead, you'll have to use the SVD operation to get the row of V associated with the smallest singular value of the design matrix. Test that you get the same result from OpenCV's SVD operation and Octave's <code>null()</code> function.\n",
    "\n",
    "Once you've got a homography that works for the selected quadrilateral, you'll want to adjust it by incorporating a translation that maps the bounding box of the transformed image to a valid range starting at 0 for the uppermost Y coordinate and leftmost X coordinate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display rectified image\n",
    "\n",
    "Once you've got that working, you'll want to display a rectified version of the original image in a second HighGUI window as we step through the video. There are two ways to do this: directly (manually) and using <code>cv::warpPerspective()</code>. For this lab's learning outcomes, it would be better for you to do it directly/manually using bilinear interpolation. This will give you a better understanding of how to render image transforms. In your own work later, go ahead and use <code>warpPerspective()</code> or whatever suits you.\n",
    "\n",
    "### Display original and rectified optical flows\n",
    "Once you have the display of the original and ground-plane-rectified images working, add the optical flows from Lab 01 and render them in both images. This will be really useful.\n",
    "\n",
    "One of the example is using <code>getPerspectiveTransfrom()</code> to get homograpy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Put the code in the main function\n",
    "\n",
    "    if (pts.size() == 4)\n",
    "    {\n",
    "        Point2f src[4];\n",
    "        for (int i = 0; i < 4; i++)\n",
    "        {\n",
    "            src[i].x = pts[i].x * 1.0;\n",
    "            src[i].y = pts[i].y * 1.0;\n",
    "        }\n",
    "        Point2f reals[4];\n",
    "        reals[0] = Point2f(800.0, 800.0);\n",
    "        reals[1] = Point2f(1000.0, 800.0);\n",
    "        reals[2] = Point2f(1000.0, 1000.0);\n",
    "        reals[3] = Point2f(800.0, 1000.0);\n",
    "\n",
    "        Mat homography_matrix = getPerspectiveTransform(src, reals);\n",
    "        std::cout << \"Estimated Homography Matrix is:\" << std::endl;\n",
    "        std::cout << homography_matrix << std::endl;\n",
    "\n",
    "        // perspective transform operation using transform matrix\n",
    "        cv::warpPerspective(matPauseScreen, matResult, homography_matrix, matPauseScreen.size(), cv::INTER_LINEAR);\n",
    "        imshow(\"Source\", matPauseScreen);\n",
    "        imshow(\"Result\", matResult);\n",
    "\n",
    "        waitKey(0);\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if (len(pts) == 4):\n",
    "        src = np.array(pts).astype(np.float32)\n",
    "\n",
    "        reals = np.array([(800, 800),\n",
    "                          (1000, 800),\n",
    "                          (1000, 1000),\n",
    "                          (800, 1000)], np.float32)\n",
    "\n",
    "        homography_matrix = cv2.getPerspectiveTransform(src, reals);\n",
    "        print(\"Estimated Homography Matrix is:\")\n",
    "        print(homography_matrix)\n",
    "\n",
    "        # perspective transform operation using transform matrix\n",
    "\n",
    "        h, w, ch = matPauseScreen.shape\n",
    "        matResult = cv2.warpPerspective(matPauseScreen, homography_matrix, (w, h), cv2.INTER_LINEAR)\n",
    "        matPauseScreen = cv2.resize(matPauseScreen, dim)\n",
    "        cv2.imshow(\"Source\", matPauseScreen)\n",
    "        matResult = cv2.resize(matResult, dim)\n",
    "        cv2.imshow(\"Result\", matResult)\n",
    "\n",
    "        cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The result should be like this\n",
    "\n",
    "<img src=\"img/lab02-3.PNG\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reuse the homography from your last run\n",
    "Learn how OpenCV stores data files in YML format using the FileStorage class. When the user selects four points in a frame, output the resulting homography to a data file and re-read that file when the program starts again. That way, the use only has to do the \"calibration\" once.\n",
    "\n",
    "### What to turn in\n",
    "Write a brief report and turn in to the instructor before the next lab. Make a video showing the frames of the original video with optical flows side-by-side with the rectified image and rectified optical flows, put the video online, and point to it on the Piazza discussion board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
