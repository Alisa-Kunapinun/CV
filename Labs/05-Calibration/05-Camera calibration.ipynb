{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision, Lab 4: Camera and lens\n",
    "\n",
    "Reference:\n",
    "\n",
    " - https://docs.opencv.org/master/d4/d94/tutorial_camera_calibration.html\n",
    " - Halcon Manual\n",
    " - https://www.baslerweb.com/\n",
    " - https://www.baslerweb.com/en/products/tools/lens-selector/\n",
    " - https://docs.opencv.org/master/dc/dbb/tutorial_py_calibration.html\n",
    " - https://learnopencv.com/camera-calibration-using-opencv/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera System\n",
    "\n",
    "Camera system is an important module in Machine vision system. The sytem is connected to the overall system as below:\n",
    "\n",
    "<img src=\"img/lab04-1.png\" width=\"600\"/>\n",
    "\n",
    "The parameters which are used in the camera system:\n",
    "\n",
    " 1. Resolution: Size of image in width x height\n",
    " 2. Field of View (FOV): The area which camera can capture\n",
    " 3. Working Distance (WD): The length between camera and object\n",
    " 4. Sensor Size: Size of sensor ship in digital camera\n",
    " 5. Depth of Field (DOF): Maximum blur allowable to obtain desired resolution\n",
    " 6. Image       \n",
    " 7. Pixel: Unit type of image size\n",
    " 8. Pixel Resolution: size of pixel which allow to take object which minimum size\n",
    " 9. Focal Length: Focus of lens\n",
    "\n",
    "<img src=\"img/lab04-2.png\" width=\"800\"/>\n",
    "\n",
    "<img src=\"img/lab04-3.png\" width=\"400\"/>\n",
    "\n",
    " 11. Magnification: The scale between Sensor size and FOV\n",
    " \n",
    "\\begin{equation}\n",
    "Magnification = \\frac{sensorSize(mm)}{FOV(mm)}\n",
    "\\end{equation}\n",
    " \n",
    "### Image Sensor\n",
    " \n",
    " When an image go to the image sensor, it will save the data of each pixel and send out to be an image. The image sensor types in industrial are:\n",
    " - CMOS\n",
    " - CCD\n",
    " \n",
    " In the past CCD type is better than CMOS. However, it is more expensive than CMOS type. Nowaday, as the higher technology, CMOS quality is equally compared to CCD. Thus, mostly of current product cameras are CMOS.\n",
    " \n",
    " Image sensor size is the main of adjusting quality of image output. The bigger of sensor size, the more quality you get. Normally, the scale of sensors size between width and height is 4:3. Moreover, the bigger sensor size can make image bigger when connect to lens.\n",
    " \n",
    "<img src=\"img/lab04-4.png\" width=\"500\"/>\n",
    " \n",
    "### Resolution\n",
    "\n",
    "<img src=\"img/lab04-5.jpg\" width=\"400\"/>\n",
    "\n",
    "### How to know the resolution is suitable for your work?\n",
    "\n",
    "To find the suitable resolution, there is a resolution chart to check.\n",
    "\n",
    "<img src=\"img/lab04-6.jpg\" width=\"800\"/>\n",
    "\n",
    "In another way, we can calculate the pixel size.\n",
    "\n",
    "\\begin{equation}\n",
    "pixelsize = \\frac{Resolution}{sensorSize(mm)}\n",
    "\\end{equation}\n",
    "\n",
    "### Frame rate\n",
    "\n",
    "How fast you want? Frame rate is your answer. It tells you how fast of an image to process from camera and send to computer system. The frame rate type is frame per sec (fps)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lens specification\n",
    "\n",
    "Lens specification can be separate into 2 types: Focal Length and Aperture (F-Stop)\n",
    "\n",
    "### Aperture (F-Stop)\n",
    "\n",
    "Aperture (or in comercial camer called **F-Stop**) tell how width of the opening lens. It can say as the divide number with the focal length.\n",
    "\n",
    "\\begin{equation}aperture = \\frac{f}{apertureScale}\\end{equation}\n",
    "\n",
    "Thus, the smaller number of aperture can recieve light more than the bigger number.\n",
    "\n",
    "<img src=\"img/lab04-7.jpg\" width=\"600\"/>\n",
    "\n",
    "#### The effect of aperture\n",
    "\n",
    "- Light is bright or dark\n",
    "\n",
    "<img src=\"img/lab04-9.jpg\" width=\"600\"/>\n",
    "\n",
    "- Bigger number of aperture makes light act like star.\n",
    "\n",
    "<img src=\"img/lab04-8.jpg\" width=\"500\"/>\n",
    "\n",
    "- Bigger number of aperture makes DOF wider\n",
    "\n",
    "<img src=\"img/lab04-10.jpg\" width=\"500\"/>\n",
    "\n",
    "### Focal length\n",
    "\n",
    "- Unit type is mm\n",
    "- The more number of the lens, the smaller beam area image get.\n",
    "\n",
    "<img src=\"img/lab04-11.png\" width=\"1000\"/>\n",
    "\n",
    "- If the number is small, the object area which can get into camera will be bigger. However, the image will have **distortion**\n",
    "\n",
    "<img src=\"img/lab04-12.png\" width=\"800\"/>\n",
    "\n",
    "<img src=\"img/lab04-13.gif\" width=\"400\"/>\n",
    "\n",
    "### Perspective\n",
    "\n",
    "When camera has been setup in the wrong direction/rotation, the object shape has been tilt as rectangle. It can be address by using 4 ponts homography.\n",
    "\n",
    "### Distortion\n",
    "\n",
    "Distortion is the tilt geometric of image input. It happens from the lens mechanism. Normally, the distortion has curve like **Radial Distortion** from the center of field of view.\n",
    "\n",
    "Distortion can be solved by:\n",
    "- Change lens to be telecentric lens (Hardware technics, expensive)\n",
    "- Use camera calibration called **Spatial Calibration**\n",
    "\n",
    "<img src=\"img/lab04-14.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric Camera parameters\n",
    "\n",
    "So... as the fundamental camera at above, we can calculate the camera parameters in geometric form. The equations has been described in the camera reference frame and the image coordinate have their origin at the principal point.\n",
    "\n",
    "<img src=\"img/lab04-15.gif\" width=\"600\"/>\n",
    "\n",
    "### Types of parameters\n",
    "\n",
    "There are 2 types of parameters need to be calculate to reconstruct the 3D structure of a scene from the pixel coordinates of image points.\n",
    "\n",
    "1. Extrinsic camera parameters: the parameters which define location and orientation of the camera reference frame to world reference frame\n",
    "2. Intrinsic camera parameters: the parameters whick link the pixel coordinates of an image point with the corresponding coordinates in the camera reference frame.\n",
    "\n",
    "<img src=\"img/lab04-17.png\" width=\"400\"/>\n",
    "\n",
    "<img src=\"img/lab04-16.png\" width=\"600\"/>\n",
    "\n",
    "As the chart above, we can determine camera coordinate from world coordinate with intrinsic and extrinsic matrix as:\n",
    "\n",
    "\\begin{equation}\n",
    "P_c = \\begin{bmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "1\n",
    "\\end{bmatrix} = K \\times P_w = A\\begin{bmatrix}R | t\\end{bmatrix} \\begin{bmatrix}\n",
    "X \\\\\n",
    "Y \\\\\n",
    "Z \\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "When\n",
    " - $P_c$: Camera point\n",
    " - $P_w$: world point\n",
    " - $K$: Camera matrix where\n",
    "\n",
    "\\begin{equation}K = intrinsic \\times extrinsic = A\n",
    "\\begin{bmatrix}\n",
    "R | t\n",
    "\\end{bmatrix}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrinsic camera parameters\n",
    "\n",
    "The parameters mean\n",
    "\n",
    "1. finding the translation vector between the relative positions of the origins of the two reference frames.\n",
    "2. finding the rotation matrix that brings the corresponding axes of the two frames into alignment (i.e., onto each other)\n",
    "\n",
    "Using the extrinsic camera parameters, we can find the relation between the coordinates of a point P in world ($P_w$) and image plane ($P_{im}$) coordinates:\n",
    "\n",
    "\\begin{equation}\n",
    "P_{im} = R(P_w - T) = [R|t]P_w\n",
    "\\end{equation}\n",
    "\n",
    "Where\n",
    "\\begin{equation}\n",
    "[R | t] =\n",
    "\\begin{bmatrix}\n",
    "r_{11} & r_{12} & r_{13} & t_1\\\\\n",
    "r_{21} & r_{22} & r_{23} & t_2\\\\\n",
    "r_{31} & r_{32} & r_{33} & t_3\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "if \n",
    "$P_{im} =\n",
    "\\begin{bmatrix}\n",
    "X_{im}\\\\\n",
    "Y_{im}\\\\\n",
    "Z_{im}\n",
    "\\end{bmatrix}$ and \n",
    "$P_w =\n",
    "\\begin{bmatrix}\n",
    "X_w\\\\\n",
    "Y_w\\\\\n",
    "Z_w\\\\\n",
    "1\n",
    "\\end{bmatrix}$ then\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "X_{im}\\\\\n",
    "Y_{im}\\\\\n",
    "Z_{im}\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "r_{11} & r_{12} & r_{13} & t_1\\\\\n",
    "r_{21} & r_{22} & r_{23} & t_2\\\\\n",
    "r_{31} & r_{32} & r_{33} & t_3\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "X_w\\\\\n",
    "Y_w\\\\\n",
    "Z_w\\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "As $R$ is a rotation matrix, we can adjust the rotation matrix in 3 styles\n",
    "\n",
    "- Euclidian matrix: (rotate) $\\begin{bmatrix}\n",
    "cos(\\theta) & -sin(\\theta) & 0\\\\\n",
    "sin(\\theta) & cos(\\theta) & 0\\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}$\n",
    "- Projective matrix: (scale, shear, rotate)\n",
    "$\\begin{bmatrix}\n",
    "r_{11} & r_{12} & 0\\\\\n",
    "r_{21} & r_{22} & 0\\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}$\n",
    "- Affine matrix: (perspective, scale, shear, rotate) $\\begin{bmatrix}\n",
    "r_{11} & r_{12} & r_{13}\\\\\n",
    "r_{21} & r_{22} & r_{23}\\\\\n",
    "r_{31} & r_{32} & r_{33}\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intrinsic camera parameters\n",
    "\n",
    "These are the parameters that characterize the optical, geometric, and digital characteristics of the camera:\n",
    "1. the perspective projection (focal length f ).\n",
    "2. the transformation between image plane coordinates and pixel coordinates.\n",
    "3. the geometric distortion introduced by the optics.\n",
    "\n",
    "### From Camera Coordinates to Image Plane Coordinates\n",
    "\n",
    "- Apply perspective projection\n",
    "\n",
    "$x = f\\frac{X_c}{Z_c}$, $y = f\\frac{X_c}{Z_c}$\n",
    "\n",
    "### From Image Plane Coordinates to Pixel coordinates\n",
    "\n",
    "<img src=\"img/lab04-18.png\" width=\"600\"/>\n",
    "\n",
    "- Using matrix notation\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "x\\\\\n",
    "y\\\\\n",
    "1\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "\\alpha_x & s & x_0\\\\\n",
    "0 & \\alpha_y & y_0\\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "X_{im}\\\\\n",
    "Y_{im}\\\\\n",
    "Z_{im}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "### From world coordinate to pixel coordinate\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "x\\\\\n",
    "y\\\\\n",
    "1\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "\\alpha_x & s & x_0\\\\\n",
    "0 & \\alpha_y & y_0\\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "r_{11} & r_{12} & r_{13} & t_1\\\\\n",
    "r_{21} & r_{22} & r_{23} & t_2\\\\\n",
    "r_{31} & r_{32} & r_{33} & t_3\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "X_w\\\\\n",
    "Y_w\\\\\n",
    "Z_w\\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Finally,\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "x\\\\\n",
    "y\\\\\n",
    "1\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "m_{11} & m_{12} & m_{13} & m_{14}\\\\\n",
    "m_{21} & m_{22} & m_{23} & m_{24}\\\\\n",
    "m_{31} & m_{32} & m_{33} & m_{34}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "X_w\\\\\n",
    "Y_w\\\\\n",
    "Z_w\\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image distortions due to optics\n",
    "\n",
    "As the image input might have curve from lens, we must rectify the pixel coordinate before calculate world coordinate using intrinsic and extrinsic matrix. We assume that $(x_d, y_d)$ is the pixel coordinate of distorted points before rectify image. The equation in opencv are\n",
    "\n",
    "\\begin{equation}\n",
    "x = (x_d - x_c)(1+k_1r^2+k_2r^4 + k_3r^6)\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "y = (y_d-y_c)(1+k_1r^2+k_2r^4 + k_3r^6)\n",
    "\\end{equation}\n",
    "\n",
    "When $r^2 = (x_d - x_c)^2+(y_d - y_c)^2$, and $k_1$ and $k_2$ are intrinsic parameters.\n",
    "\n",
    "The presence of the radial distortion manifests in form of the \"barrel\" or \"fish-eye\" effect.\n",
    "\n",
    "Tangential distortion occurs because the image taking lenses are not perfectly parallel to the imaging plane. It can be represented via the formulas:\n",
    "\n",
    "\\begin{equation}\n",
    "x = x_d+(2p_1(x_d - x_c)(y_d - x_c) + p_2(r^2+2(x_d-x_c)^2))\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "y = y_d+(2p_1(r^2+2(y_d - y_c)^2)+2p_2(x_d - x_c)(y_d - y_c))\n",
    "\\end{equation}\n",
    "\n",
    "finally,\n",
    "\n",
    "\\begin{equation}\n",
    "x = x_d + (x_d - x_c)(1+k_1r^2+k_2r^4 + k_3r^6) +(2p_1(x_d - x_c)(y_d - x_c) + p_2(r^2+2(x_d-x_c)^2))\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "y = y_d + (y_d-y_c)(1+k_1r^2+k_2r^4 + k_3r^6) +(2p_1(r^2+2(y_d - y_c)^2)+2p_2(x_d - x_c)(y_d - y_c))\n",
    "\\end{equation}\n",
    "\n",
    "Thus we have 5 distortion parameters which in openCV are presented as 1 row matrix with 5 columns:\n",
    "\n",
    "\\begin{equation}C = distortionCoefficients=\\begin{bmatrix}k1 & k2 & p1 & p2 &k3\\end{bmatrix}\\end{equation}\n",
    "\n",
    "\n",
    "# Dr. Matt, please check\n",
    "# we can have $(x_d,y_d)$ but no $(x,y)$\n",
    "We can make C matrix by:\n",
    "\n",
    "\\begin{equation}\n",
    "0 = AC'\n",
    "\\end{equation}\n",
    "\n",
    "When C is\n",
    "\\begin{equation}C = distortionCoefficients=\\begin{bmatrix}k1 & k2 & p1 & p2 &k3 & 1\\end{bmatrix}\\end{equation}\n",
    "\n",
    "and A is\n",
    "\n",
    "\\begin{equation}\n",
    "A = \n",
    "\\begin{bmatrix}\n",
    "r^2(x_d-x_c) & r^4(x_d-x_c) & 2(x_d - x_c)(y_d - x_c) & (r^2+2(x_d-x_c)^2) & r^6(x_d-x_c) & (2x_d - x_c - x) \\\\\n",
    "r^2(y_d-y_c) & r^4(y_d-y_c) & (r^2+2(y_d-y_c)^2) & 2(x_d - x_c)(y_d - x_c) & r^6(y_d-y_c) & (2y_d - y_c - y)\n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration\n",
    "\n",
    "The calibration process is explained by a flowchart given below.\n",
    "\n",
    "<img src=\"img/lab04-22.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chessboard calibration\n",
    "\n",
    "#### 0. Firs of all, save and print the image (Chessboard) for use in camera.\n",
    "\n",
    "<img src=\"img/lab04-19.png\" width=\"600\"/>\n",
    "\n",
    "There are many patterns for calibration. However, openCV supports 3 patterns:\n",
    "- Classical black-white chessboard (Image above)\n",
    "- Symmetrical circle pattern\n",
    "\n",
    "<img src=\"img/lab04-21.png\" width=\"600\"/>\n",
    "\n",
    "- Asymmetrical circle pattern\n",
    "\n",
    "#### 1. Define real world coordinates with checkerboard pattern\n",
    "\n",
    "In the process of calibration we calculate the camera parameters by a set of know 3D points $(X_w, Y_w, Z_w)$ and their corresponding pixel location $(u,v)$ in the image.\n",
    "\n",
    "For the 3D points we photograph a checkerboard pattern with known dimensions at many different orientations. The world coordinate is attached to the checkerboard and since all the corner points lie on a plane, we can arbitrarily choose Z_w for every point to be 0. Since points are equally spaced in the checkerboard, the $(X_w, Y_w)$ coordinates of each 3D point are easily defined by taking one point as reference $(0, 0)$ and defining remaining with respect to that reference point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a program to get the image from camera or video.\n",
    "\n",
    "If you use web camera, code example is at below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <opencv2/opencv.hpp>\n",
    "#include <iostream>\n",
    "\n",
    "using namespace cv;\n",
    "using namespace std;\n",
    "int main()\n",
    "{\n",
    "    int frameAdd = 0;\n",
    "    Mat frame;\n",
    "    int iKey = -1;\n",
    "    //--- INITIALIZE VIDEOCAPTURE\n",
    "    VideoCapture cap;\n",
    "    // open the default camera using default API\n",
    "    // cap.open(0);\n",
    "    // OR advance usage: select any API backend\n",
    "    int deviceID = 0;             // 0 = open default camera\n",
    "    int apiID = cv::CAP_ANY;      // 0 = autodetect default API\n",
    "    // open selected camera using selected API\n",
    "    cap.open(deviceID, apiID);\n",
    "    // check if we succeeded\n",
    "    if (!cap.isOpened()) {\n",
    "        cerr << \"ERROR! Unable to open camera\\n\";\n",
    "        return -1;\n",
    "    }\n",
    "    //--- GRAB AND WRITE LOOP\n",
    "    cout << \"Start grabbing\" << endl\n",
    "        << \"Press s to save images and q to terminate\" << endl;\n",
    "    for (;;)\n",
    "    {\n",
    "        // wait for a new frame from camera and store it into 'frame'\n",
    "        cap.read(frame);\n",
    "        // check if we succeeded\n",
    "        if (frame.empty()) {\n",
    "            cerr << \"ERROR! blank frame grabbed\\n\";\n",
    "            break;\n",
    "        }\n",
    "        // show live and wait for a key with timeout long enough to show images\n",
    "        imshow(\"Live\", frame);\n",
    "        iKey = waitKey(5);\n",
    "        if (iKey == 's' || iKey == 'S')\n",
    "        {\n",
    "            imwrite(\"./images/frame\" + to_string(frameAdd) + \".jpg\", frame);\n",
    "            wantFrame[frameAdd] = frame.clone();\n",
    "            frameAdd++;\n",
    "            count << \"Frame: \" << frameAdd << \" has been saved.\" << endl;\n",
    "        }\n",
    "        else if (iKey == 'q' || iKey == 'Q')\n",
    "        {\n",
    "            break;\n",
    "        }\n",
    "    }\n",
    "    // the camera will be deinitialized automatically in VideoCapture destructor\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "cap = cv2.VideoCapture()\n",
    "cap.open(0, cv2.CAP_ANY);\n",
    "if not cap.isOpened():\n",
    "    print(\"ERROR! Unable to open camera\\n\")\n",
    "    exit()\n",
    "print(\"Start grabbing\")\n",
    "print(\"Press s to save images and q to terminate\")\n",
    "frameAdd = 0\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    if frame is None:\n",
    "        print(\"ERROR! blank frame grabbed\\n\")\n",
    "        exit()\n",
    "    cv2.imshow(\"Live\", frame)\n",
    "    iKey = cv2.waitKey(5)\n",
    "    if iKey == ord('s') or iKey == ord('S'):\n",
    "        cv2.imwrite(\"./images/frame\" + str(frameAdd) + \".jpg\", frame)\n",
    "        frameAdd += 1\n",
    "        print(\"Frame: \", frameAdd, \" has been saved.\")\n",
    "    elif iKey == ord('q') or iKey == ord('Q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the web camera, you will see the camera with chessboard as below:\n",
    "\n",
    "<img src=\"img/lab04-20.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2. Take several pictures for the checkerboard (generally more than 10)\n",
    "\n",
    "Save and put them to <code>./images</code>\n",
    "\n",
    "<img src=\"img/lab04-23.gif\" width=\"300\"/>\n",
    "\n",
    "There are two cases here\n",
    "\n",
    "    (1) To calibrate the distortion coefficient and camera internal parameters, the photographs need to contain a complete\n",
    "    chessboard, and at the same time require different distances, different orientations, and different tilt angles of the\n",
    "    chess board.\n",
    "\n",
    "    (2) Calibration distortion coefficient, camera internal parameters and camera external parameters. The picture contains\n",
    "    the above requirements. At the same time, each photo in the calibration program generated results will calculate an\n",
    "    external camera parameter. Therefore, according to actual needs, add a few photos of the chessboard at the working\n",
    "    position. (It is recommended to use the solvePnP function to obtain external camera parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 1. Find checkerboard corners\n",
    "\n",
    "OpenCV provides a builtin function called findChessboardCorners that looks for a checkerboard and returns the coordinates of the corners. Let’ see the usage in the code block below. Its usage is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool findChessboardCorners(InputArray image, \n",
    "                           Size patternSize, \n",
    "                           OutputArray corners, \n",
    "                           int flags=CALIB_CB_ADAPTIVE_THRESH+CALIB_CB_NORMALIZE_IMAGE );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retval, corners = cv2.findChessboardCorners(image, patternSize, flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable | Meaning |\n",
    "| :--- | :--- |\n",
    "| **image** | Source chessboard view. It must be an 8-bit grayscale or color image. |\n",
    "| **patternSize** | Number of inner corners per a chessboard row and column ( patternSize = cvSize (points_per_row, points_per_colum) = cvSize(columns,rows) ). |\n",
    "| **corners** | Output array of detected corners. |\n",
    "| **flags** | Various operation flags. You have to worry about these only when things do not work well. Go with the default. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  3. 2. Refine checkerboard corners\n",
    "\n",
    "Good calibration is all about precision. To get good results it is important to obtain the location of corners with sub-pixel level of accuracy.\n",
    "\n",
    "OpenCV’s function cornerSubPix takes in the original image, and the location of corners, and looks for the best corner location inside a small neighborhood of the original location. The algorithm is iterative in nature and therefore we need to specify the termination criteria ( e.g. number of iterations and/or the accuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool findChessboardCorners(InputArray image, \n",
    "                           Size patternSize,\n",
    "                           OutputArray corners,\n",
    "                           int flags = CALIB_CB_ADAPTIVE_THRESH + CALIB_CB_NORMALIZE_IMAGE );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retval, corners = cv2.findChessboardCorners(image, patternSize, flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable | Meaning |\n",
    "| :--- | :--- |\n",
    "| **image** | Input image. |\n",
    "| **corners** | Initial coordinates of the input corners and refined coordinates provided for output. |\n",
    "| **winSize** | Half of the side length of the search window. |\n",
    "| **zeroZone** | Half of the size of the dead region in the middle of the search zone over which the summation in the formula below is not done. It is used sometimes to avoid possible singularities of the autocorrelation matrix. The value of (-1,-1) indicates that there is no such a size. |\n",
    "|**criteria** | Criteria for termination of the iterative process of corner refinement. That is, the process of corner position refinement stops either after criteria.maxCount iterations or when the corner position moves by less than criteria.epsilon on some iteration.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Calibrate Camera\n",
    "\n",
    "The final step of calibration is to pass the 3D points in world coordinates and their 2D locations in all images to OpenCV’s calibrateCamera method. The implementation is based on a paper by Zhengyou Zhang. The math is a bit involved and requires a background in linear algebra.\n",
    "\n",
    "Let’s look at the syntax for calibrateCamera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double calibrateCamera(InputArrayOfArrays objectPoints,\n",
    "                       InputArrayOfArrays imagePoints,\n",
    "                       Size imageSize,\n",
    "                       InputOutputArray cameraMatrix,\n",
    "                       InputOutputArray distCoeffs,\n",
    "                       OutputArrayOfArrays rvecs,\n",
    "                       OutputArrayOfArrays tvecs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retval, cameraMatrix, distCoeffs, rvecs, tvecs = cv2.calibrateCamera(objectPoints, imagePoints, imageSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable | Meaning |\n",
    "| :--- | :--- |\n",
    "| **objectPoints** | A vector of vector of 3D points. The outer vector contains as many elements as the number of the pattern views. |\n",
    "| **imagePoints** | A vector of vectors of the 2D image points. |\n",
    "| **imageSize** | Size of the image |\n",
    "| **cameraMatrix** | Intrinsic camera matrix |\n",
    "|**distCoeffs** | Lens distortion coefficients. These coefficients will be explained in a future post.|\n",
    "| **rvecs** | Rotation specified as a 3×1 vector. The direction of the vector specifies the axis of rotation and the magnitude of the vector specifies the angle of rotation. |\n",
    "| **tvecs** | 3×1 Translation vector. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full code of camera calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <opencv2/opencv.hpp>\n",
    "#include <opencv2/calib3d/calib3d.hpp>\n",
    "#include <opencv2/highgui/highgui.hpp>\n",
    "#include <opencv2/imgproc/imgproc.hpp>\n",
    "#include <stdio.h>\n",
    "#include <iostream>\n",
    "\n",
    "// Defining the dimensions of checkerboard\n",
    "int CHECKERBOARD[2]{8,11}; // width, height\n",
    "\n",
    "int main()\n",
    "{\n",
    "  // Creating vector to store vectors of 3D points for each checkerboard image\n",
    "  std::vector<std::vector<cv::Point3f> > objpoints;\n",
    "\n",
    "  // Creating vector to store vectors of 2D points for each checkerboard image\n",
    "  std::vector<std::vector<cv::Point2f> > imgpoints;\n",
    "\n",
    "  // Defining the world coordinates for 3D points\n",
    "  std::vector<cv::Point3f> objp;\n",
    "  for(int i = 0; i<CHECKERBOARD[1]; i++)\n",
    "  {\n",
    "    for(int j = 0; j<CHECKERBOARD[0]; j++)\n",
    "      objp.push_back(cv::Point3f(j,i,0));\n",
    "  }\n",
    "\n",
    "\n",
    "  // Extracting path of individual image stored in a given directory\n",
    "  std::vector<cv::String> images;\n",
    "  // Path of the folder containing checkerboard images\n",
    "  std::string path = \"./images/*.jpg\";\n",
    "\n",
    "  cv::glob(path, images);\n",
    "\n",
    "  cv::Mat frame, gray;\n",
    "  // vector to store the pixel coordinates of detected checker board corners \n",
    "  std::vector<cv::Point2f> corner_pts;\n",
    "  bool success;\n",
    "\n",
    "  // Looping over all the images in the directory\n",
    "  for(int i{0}; i<images.size(); i++)\n",
    "  {\n",
    "    frame = cv::imread(images[i]);\n",
    "    cv::cvtColor(frame,gray,cv::COLOR_BGR2GRAY);\n",
    "\n",
    "    // Finding checker board corners\n",
    "    // If desired number of corners are found in the image then success = true  \n",
    "    success = cv::findChessboardCorners(gray, cv::Size(CHECKERBOARD[0], CHECKERBOARD[1]), corner_pts, CV_CALIB_CB_ADAPTIVE_THRESH | CV_CALIB_CB_FAST_CHECK | CV_CALIB_CB_NORMALIZE_IMAGE);\n",
    "    \n",
    "    /* \n",
    "     * If desired number of corner are detected,\n",
    "     * we refine the pixel coordinates and display \n",
    "     * them on the images of checker board\n",
    "    */\n",
    "    if(success)\n",
    "    {\n",
    "      cv::TermCriteria criteria(CV_TERMCRIT_EPS | CV_TERMCRIT_ITER, 30, 0.001);\n",
    "      \n",
    "      // refining pixel coordinates for given 2d points.\n",
    "      cv::cornerSubPix(gray,corner_pts,cv::Size(11,11), cv::Size(-1,-1),criteria);\n",
    "      \n",
    "      // Displaying the detected corner points on the checker board\n",
    "      cv::drawChessboardCorners(frame, cv::Size(CHECKERBOARD[0], CHECKERBOARD[1]), corner_pts, success);\n",
    "      \n",
    "      objpoints.push_back(objp);\n",
    "      imgpoints.push_back(corner_pts);\n",
    "    }\n",
    "\n",
    "    cv::imshow(\"Image\",frame);\n",
    "    cv::waitKey(0);\n",
    "  }\n",
    "\n",
    "  cv::destroyAllWindows();\n",
    "\n",
    "  cv::Mat cameraMatrix,distCoeffs,R,T;\n",
    "\n",
    "  /*\n",
    "   * Performing camera calibration by \n",
    "   * passing the value of known 3D points (objpoints)\n",
    "   * and corresponding pixel coordinates of the \n",
    "   * detected corners (imgpoints)\n",
    "  */\n",
    "  cv::calibrateCamera(objpoints, imgpoints, cv::Size(gray.rows,gray.cols), cameraMatrix, distCoeffs, R, T);\n",
    "\n",
    "  std::cout << \"cameraMatrix : \" << cameraMatrix << std::endl;\n",
    "  std::cout << \"distCoeffs : \" << distCoeffs << std::endl;\n",
    "  std::cout << \"Rotation vector : \" << R << std::endl;\n",
    "  std::cout << \"Translation vector : \" << T << std::endl;\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Defining the dimensions of checkerboard\n",
    "CHECKERBOARD = (8,11)\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Creating vector to store vectors of 3D points for each checkerboard image\n",
    "objpoints = []\n",
    "# Creating vector to store vectors of 2D points for each checkerboard image\n",
    "imgpoints = [] \n",
    "\n",
    "\n",
    "# Defining the world coordinates for 3D points\n",
    "objp = np.zeros((1, CHECKERBOARD[0] * CHECKERBOARD[1], 3), np.float32)\n",
    "objp[0,:,:2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1, 2)\n",
    "prev_img_shape = None\n",
    "\n",
    "# Extracting path of individual image stored in a given directory\n",
    "images = glob.glob('./images/*.jpg')\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chess board corners\n",
    "    # If desired number of corners are found in the image then ret = true\n",
    "    ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD, cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "    \n",
    "    \"\"\"\n",
    "    If desired number of corner are detected,\n",
    "    we refine the pixel coordinates and display \n",
    "    them on the images of checker board\n",
    "    \"\"\"\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        # refining pixel coordinates for given 2d points.\n",
    "        corners2 = cv2.cornerSubPix(gray, corners, (11,11),(-1,-1), criteria)\n",
    "        \n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, CHECKERBOARD, corners2, ret)\n",
    "    \n",
    "    cv2.imshow('img',img)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "h,w = img.shape[:2]\n",
    "\n",
    "\"\"\"\n",
    "Performing camera calibration by \n",
    "passing the value of known 3D points (objpoints)\n",
    "and corresponding pixel coordinates of the \n",
    "detected corners (imgpoints)\n",
    "\"\"\"\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "print(\"Camera matrix : \\n\")\n",
    "print(mtx)\n",
    "print(\"dist : \\n\")\n",
    "print(dist)\n",
    "print(\"rvecs : \\n\")\n",
    "print(rvecs)\n",
    "print(\"tvecs : \\n\")\n",
    "print(tvecs)\n",
    "\n",
    "# Show images of undistorted\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    res = cv2.undistort(img, mtx, dist)\n",
    "    cv2.imshow('img',img)\n",
    "    cv2.imshow('res',res)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of the images\n",
    "\n",
    "You can see the result like this.\n",
    "\n",
    "Source image\n",
    "<img src=\"img/lab04-26.png\" width=\"600\"/>\n",
    "\n",
    "Chessboard detection\n",
    "<img src=\"img/lab04-24.png\" width=\"600\"/>\n",
    "\n",
    "Rectified image\n",
    "<img src=\"img/lab04-25.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More fancier in undistorted\n",
    "\n",
    "After undistorted, the result of rectified image may need to be crops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Way 1: This is the easiest way. Just call the function and use ROI obtained above to crop the result.\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    h,  w = img.shape[:2]\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "    \n",
    "    res = cv2.undistort(img, mtx, dist)\n",
    "    \n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    res = res[y:y+h, x:x+w]\n",
    "    \n",
    "    cv2.imshow('img',img)\n",
    "    cv2.imshow('res',res)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Way 2: This way is a little bit more difficult. \n",
    "# First, find a mapping function from the distorted image to the undistorted image.\n",
    "# Then use the remap function.\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    h,  w = img.shape[:2]\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "    \n",
    "    mapx, mapy = cv2.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (w,h), 5)\n",
    "    res = cv2.remap(img, mapx, mapy, cv.INTER_LINEAR)\n",
    "    \n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    res = res[y:y+h, x:x+w]\n",
    "    \n",
    "    cv2.imshow('img',img)\n",
    "    cv2.imshow('res',res)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-projection Error\n",
    "\n",
    "Re-projection error gives a good estimation of just how exact the found parameters are. The closer the re-projection error is to zero, the more accurate the parameters we found are. Given the intrinsic, distortion, rotation and translation matrices, we must first transform the object point to image point using cv.projectPoints(). Then, we can calculate the absolute norm between what we got with our transformation and the corner finding algorithm. To find the average error, we calculate the arithmetical mean of the errors calculated for all the calibration images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv.norm(imgpoints[i], imgpoints2, cv.NORM_L2)/len(imgpoints2)\n",
    "    mean_error += error\n",
    "print( \"total error: {}\".format(mean_error/len(objpoints)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save calibration file\n",
    "\n",
    "As the result, save the calibration file into yml file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full code of Calibration from scratch\n",
    "\n",
    "Please look at https://github.com/opencv/opencv/blob/master/samples/cpp/tutorial_code/calib3d/camera_calibration/camera_calibration.cpp\n",
    "There is the source code in C++ from scratch. It may useful when you need to write it as commercial product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <sstream>\n",
    "#include <string>\n",
    "#include <ctime>\n",
    "#include <cstdio>\n",
    "\n",
    "#include <opencv2/core.hpp>\n",
    "#include <opencv2/core/utility.hpp>\n",
    "#include <opencv2/imgproc.hpp>\n",
    "#include <opencv2/calib3d.hpp>\n",
    "#include <opencv2/imgcodecs.hpp>\n",
    "#include <opencv2/videoio.hpp>\n",
    "#include <opencv2/highgui.hpp>\n",
    "\n",
    "using namespace cv;\n",
    "using namespace std;\n",
    "\n",
    "class Settings\n",
    "{\n",
    "public:\n",
    "    Settings() : goodInput(false) {}\n",
    "    enum Pattern { NOT_EXISTING, CHESSBOARD, CIRCLES_GRID, ASYMMETRIC_CIRCLES_GRID };\n",
    "    enum InputType { INVALID, CAMERA, VIDEO_FILE, IMAGE_LIST };\n",
    "\n",
    "    void write(FileStorage& fs) const                        //Write serialization for this class\n",
    "    {\n",
    "        fs << \"{\"\n",
    "                  << \"BoardSize_Width\"  << boardSize.width\n",
    "                  << \"BoardSize_Height\" << boardSize.height\n",
    "                  << \"Square_Size\"         << squareSize\n",
    "                  << \"Calibrate_Pattern\" << patternToUse\n",
    "                  << \"Calibrate_NrOfFrameToUse\" << nrFrames\n",
    "                  << \"Calibrate_FixAspectRatio\" << aspectRatio\n",
    "                  << \"Calibrate_AssumeZeroTangentialDistortion\" << calibZeroTangentDist\n",
    "                  << \"Calibrate_FixPrincipalPointAtTheCenter\" << calibFixPrincipalPoint\n",
    "\n",
    "                  << \"Write_DetectedFeaturePoints\" << writePoints\n",
    "                  << \"Write_extrinsicParameters\"   << writeExtrinsics\n",
    "                  << \"Write_gridPoints\" << writeGrid\n",
    "                  << \"Write_outputFileName\"  << outputFileName\n",
    "\n",
    "                  << \"Show_UndistortedImage\" << showUndistorted\n",
    "\n",
    "                  << \"Input_FlipAroundHorizontalAxis\" << flipVertical\n",
    "                  << \"Input_Delay\" << delay\n",
    "                  << \"Input\" << input\n",
    "           << \"}\";\n",
    "    }\n",
    "    void read(const FileNode& node)                          //Read serialization for this class\n",
    "    {\n",
    "        node[\"BoardSize_Width\" ] >> boardSize.width;\n",
    "        node[\"BoardSize_Height\"] >> boardSize.height;\n",
    "        node[\"Calibrate_Pattern\"] >> patternToUse;\n",
    "        node[\"Square_Size\"]  >> squareSize;\n",
    "        node[\"Calibrate_NrOfFrameToUse\"] >> nrFrames;\n",
    "        node[\"Calibrate_FixAspectRatio\"] >> aspectRatio;\n",
    "        node[\"Write_DetectedFeaturePoints\"] >> writePoints;\n",
    "        node[\"Write_extrinsicParameters\"] >> writeExtrinsics;\n",
    "        node[\"Write_gridPoints\"] >> writeGrid;\n",
    "        node[\"Write_outputFileName\"] >> outputFileName;\n",
    "        node[\"Calibrate_AssumeZeroTangentialDistortion\"] >> calibZeroTangentDist;\n",
    "        node[\"Calibrate_FixPrincipalPointAtTheCenter\"] >> calibFixPrincipalPoint;\n",
    "        node[\"Calibrate_UseFisheyeModel\"] >> useFisheye;\n",
    "        node[\"Input_FlipAroundHorizontalAxis\"] >> flipVertical;\n",
    "        node[\"Show_UndistortedImage\"] >> showUndistorted;\n",
    "        node[\"Input\"] >> input;\n",
    "        node[\"Input_Delay\"] >> delay;\n",
    "        node[\"Fix_K1\"] >> fixK1;\n",
    "        node[\"Fix_K2\"] >> fixK2;\n",
    "        node[\"Fix_K3\"] >> fixK3;\n",
    "        node[\"Fix_K4\"] >> fixK4;\n",
    "        node[\"Fix_K5\"] >> fixK5;\n",
    "\n",
    "        validate();\n",
    "    }\n",
    "    void validate()\n",
    "    {\n",
    "        goodInput = true;\n",
    "        if (boardSize.width <= 0 || boardSize.height <= 0)\n",
    "        {\n",
    "            cerr << \"Invalid Board size: \" << boardSize.width << \" \" << boardSize.height << endl;\n",
    "            goodInput = false;\n",
    "        }\n",
    "        if (squareSize <= 10e-6)\n",
    "        {\n",
    "            cerr << \"Invalid square size \" << squareSize << endl;\n",
    "            goodInput = false;\n",
    "        }\n",
    "        if (nrFrames <= 0)\n",
    "        {\n",
    "            cerr << \"Invalid number of frames \" << nrFrames << endl;\n",
    "            goodInput = false;\n",
    "        }\n",
    "\n",
    "        if (input.empty())      // Check for valid input\n",
    "                inputType = INVALID;\n",
    "        else\n",
    "        {\n",
    "            if (input[0] >= '0' && input[0] <= '9')\n",
    "            {\n",
    "                stringstream ss(input);\n",
    "                ss >> cameraID;\n",
    "                inputType = CAMERA;\n",
    "            }\n",
    "            else\n",
    "            {\n",
    "                if (isListOfImages(input) && readStringList(input, imageList))\n",
    "                {\n",
    "                    inputType = IMAGE_LIST;\n",
    "                    nrFrames = (nrFrames < (int)imageList.size()) ? nrFrames : (int)imageList.size();\n",
    "                }\n",
    "                else\n",
    "                    inputType = VIDEO_FILE;\n",
    "            }\n",
    "            if (inputType == CAMERA)\n",
    "                inputCapture.open(cameraID);\n",
    "            if (inputType == VIDEO_FILE)\n",
    "                inputCapture.open(input);\n",
    "            if (inputType != IMAGE_LIST && !inputCapture.isOpened())\n",
    "                    inputType = INVALID;\n",
    "        }\n",
    "        if (inputType == INVALID)\n",
    "        {\n",
    "            cerr << \" Input does not exist: \" << input;\n",
    "            goodInput = false;\n",
    "        }\n",
    "\n",
    "        flag = 0;\n",
    "        if(calibFixPrincipalPoint) flag |= CALIB_FIX_PRINCIPAL_POINT;\n",
    "        if(calibZeroTangentDist)   flag |= CALIB_ZERO_TANGENT_DIST;\n",
    "        if(aspectRatio)            flag |= CALIB_FIX_ASPECT_RATIO;\n",
    "        if(fixK1)                  flag |= CALIB_FIX_K1;\n",
    "        if(fixK2)                  flag |= CALIB_FIX_K2;\n",
    "        if(fixK3)                  flag |= CALIB_FIX_K3;\n",
    "        if(fixK4)                  flag |= CALIB_FIX_K4;\n",
    "        if(fixK5)                  flag |= CALIB_FIX_K5;\n",
    "\n",
    "        if (useFisheye) {\n",
    "            // the fisheye model has its own enum, so overwrite the flags\n",
    "            flag = fisheye::CALIB_FIX_SKEW | fisheye::CALIB_RECOMPUTE_EXTRINSIC;\n",
    "            if(fixK1)                   flag |= fisheye::CALIB_FIX_K1;\n",
    "            if(fixK2)                   flag |= fisheye::CALIB_FIX_K2;\n",
    "            if(fixK3)                   flag |= fisheye::CALIB_FIX_K3;\n",
    "            if(fixK4)                   flag |= fisheye::CALIB_FIX_K4;\n",
    "            if (calibFixPrincipalPoint) flag |= fisheye::CALIB_FIX_PRINCIPAL_POINT;\n",
    "        }\n",
    "\n",
    "        calibrationPattern = NOT_EXISTING;\n",
    "        if (!patternToUse.compare(\"CHESSBOARD\")) calibrationPattern = CHESSBOARD;\n",
    "        if (!patternToUse.compare(\"CIRCLES_GRID\")) calibrationPattern = CIRCLES_GRID;\n",
    "        if (!patternToUse.compare(\"ASYMMETRIC_CIRCLES_GRID\")) calibrationPattern = ASYMMETRIC_CIRCLES_GRID;\n",
    "        if (calibrationPattern == NOT_EXISTING)\n",
    "        {\n",
    "            cerr << \" Camera calibration mode does not exist: \" << patternToUse << endl;\n",
    "            goodInput = false;\n",
    "        }\n",
    "        atImageList = 0;\n",
    "\n",
    "    }\n",
    "    Mat nextImage()\n",
    "    {\n",
    "        Mat result;\n",
    "        if( inputCapture.isOpened() )\n",
    "        {\n",
    "            Mat view0;\n",
    "            inputCapture >> view0;\n",
    "            view0.copyTo(result);\n",
    "        }\n",
    "        else if( atImageList < imageList.size() )\n",
    "            result = imread(imageList[atImageList++], IMREAD_COLOR);\n",
    "\n",
    "        return result;\n",
    "    }\n",
    "\n",
    "    static bool readStringList( const string& filename, vector<string>& l )\n",
    "    {\n",
    "        l.clear();\n",
    "        FileStorage fs(filename, FileStorage::READ);\n",
    "        if( !fs.isOpened() )\n",
    "            return false;\n",
    "        FileNode n = fs.getFirstTopLevelNode();\n",
    "        if( n.type() != FileNode::SEQ )\n",
    "            return false;\n",
    "        FileNodeIterator it = n.begin(), it_end = n.end();\n",
    "        for( ; it != it_end; ++it )\n",
    "            l.push_back((string)*it);\n",
    "        return true;\n",
    "    }\n",
    "\n",
    "    static bool isListOfImages( const string& filename)\n",
    "    {\n",
    "        string s(filename);\n",
    "        // Look for file extension\n",
    "        if( s.find(\".xml\") == string::npos && s.find(\".yaml\") == string::npos && s.find(\".yml\") == string::npos )\n",
    "            return false;\n",
    "        else\n",
    "            return true;\n",
    "    }\n",
    "public:\n",
    "    Size boardSize;              // The size of the board -> Number of items by width and height\n",
    "    Pattern calibrationPattern;  // One of the Chessboard, circles, or asymmetric circle pattern\n",
    "    float squareSize;            // The size of a square in your defined unit (point, millimeter,etc).\n",
    "    int nrFrames;                // The number of frames to use from the input for calibration\n",
    "    float aspectRatio;           // The aspect ratio\n",
    "    int delay;                   // In case of a video input\n",
    "    bool writePoints;            // Write detected feature points\n",
    "    bool writeExtrinsics;        // Write extrinsic parameters\n",
    "    bool writeGrid;              // Write refined 3D target grid points\n",
    "    bool calibZeroTangentDist;   // Assume zero tangential distortion\n",
    "    bool calibFixPrincipalPoint; // Fix the principal point at the center\n",
    "    bool flipVertical;           // Flip the captured images around the horizontal axis\n",
    "    string outputFileName;       // The name of the file where to write\n",
    "    bool showUndistorted;        // Show undistorted images after calibration\n",
    "    string input;                // The input ->\n",
    "    bool useFisheye;             // use fisheye camera model for calibration\n",
    "    bool fixK1;                  // fix K1 distortion coefficient\n",
    "    bool fixK2;                  // fix K2 distortion coefficient\n",
    "    bool fixK3;                  // fix K3 distortion coefficient\n",
    "    bool fixK4;                  // fix K4 distortion coefficient\n",
    "    bool fixK5;                  // fix K5 distortion coefficient\n",
    "\n",
    "    int cameraID;\n",
    "    vector<string> imageList;\n",
    "    size_t atImageList;\n",
    "    VideoCapture inputCapture;\n",
    "    InputType inputType;\n",
    "    bool goodInput;\n",
    "    int flag;\n",
    "\n",
    "private:\n",
    "    string patternToUse;\n",
    "\n",
    "\n",
    "};\n",
    "\n",
    "static inline void read(const FileNode& node, Settings& x, const Settings& default_value = Settings())\n",
    "{\n",
    "    if(node.empty())\n",
    "        x = default_value;\n",
    "    else\n",
    "        x.read(node);\n",
    "}\n",
    "\n",
    "enum { DETECTION = 0, CAPTURING = 1, CALIBRATED = 2 };\n",
    "\n",
    "bool runCalibrationAndSave(Settings& s, Size imageSize, Mat&  cameraMatrix, Mat& distCoeffs,\n",
    "                           vector<vector<Point2f> > imagePoints, float grid_width, bool release_object);\n",
    "\n",
    "int main(int argc, char* argv[])\n",
    "{\n",
    "    const String keys\n",
    "        = \"{help h usage ? |           | print this message            }\"\n",
    "          \"{@settings      |default.xml| input setting file            }\"\n",
    "          \"{d              |           | actual distance between top-left and top-right corners of \"\n",
    "          \"the calibration grid }\"\n",
    "          \"{winSize        | 11        | Half of search window for cornerSubPix }\";\n",
    "    CommandLineParser parser(argc, argv, keys);\n",
    "    parser.about(\"This is a camera calibration sample.\\n\"\n",
    "                 \"Usage: camera_calibration [configuration_file -- default ./default.xml]\\n\"\n",
    "                 \"Near the sample file you'll find the configuration file, which has detailed help of \"\n",
    "                 \"how to edit it. It may be any OpenCV supported file format XML/YAML.\");\n",
    "    if (!parser.check()) {\n",
    "        parser.printErrors();\n",
    "        return 0;\n",
    "    }\n",
    "\n",
    "    if (parser.has(\"help\")) {\n",
    "        parser.printMessage();\n",
    "        return 0;\n",
    "    }\n",
    "\n",
    "    //! [file_read]\n",
    "    Settings s;\n",
    "    const string inputSettingsFile = parser.get<string>(0);\n",
    "    FileStorage fs(inputSettingsFile, FileStorage::READ); // Read the settings\n",
    "    if (!fs.isOpened())\n",
    "    {\n",
    "        cout << \"Could not open the configuration file: \\\"\" << inputSettingsFile << \"\\\"\" << endl;\n",
    "        parser.printMessage();\n",
    "        return -1;\n",
    "    }\n",
    "    fs[\"Settings\"] >> s;\n",
    "    fs.release();                                         // close Settings file\n",
    "    //! [file_read]\n",
    "\n",
    "    //FileStorage fout(\"settings.yml\", FileStorage::WRITE); // write config as YAML\n",
    "    //fout << \"Settings\" << s;\n",
    "\n",
    "    if (!s.goodInput)\n",
    "    {\n",
    "        cout << \"Invalid input detected. Application stopping. \" << endl;\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    int winSize = parser.get<int>(\"winSize\");\n",
    "\n",
    "    float grid_width = s.squareSize * (s.boardSize.width - 1);\n",
    "    bool release_object = false;\n",
    "    if (parser.has(\"d\")) {\n",
    "        grid_width = parser.get<float>(\"d\");\n",
    "        release_object = true;\n",
    "    }\n",
    "\n",
    "    vector<vector<Point2f> > imagePoints;\n",
    "    Mat cameraMatrix, distCoeffs;\n",
    "    Size imageSize;\n",
    "    int mode = s.inputType == Settings::IMAGE_LIST ? CAPTURING : DETECTION;\n",
    "    clock_t prevTimestamp = 0;\n",
    "    const Scalar RED(0,0,255), GREEN(0,255,0);\n",
    "    const char ESC_KEY = 27;\n",
    "\n",
    "    //! [get_input]\n",
    "    for(;;)\n",
    "    {\n",
    "        Mat view;\n",
    "        bool blinkOutput = false;\n",
    "\n",
    "        view = s.nextImage();\n",
    "\n",
    "        //-----  If no more image, or got enough, then stop calibration and show result -------------\n",
    "        if( mode == CAPTURING && imagePoints.size() >= (size_t)s.nrFrames )\n",
    "        {\n",
    "          if(runCalibrationAndSave(s, imageSize,  cameraMatrix, distCoeffs, imagePoints, grid_width,\n",
    "                                   release_object))\n",
    "              mode = CALIBRATED;\n",
    "          else\n",
    "              mode = DETECTION;\n",
    "        }\n",
    "        if(view.empty())          // If there are no more images stop the loop\n",
    "        {\n",
    "            // if calibration threshold was not reached yet, calibrate now\n",
    "            if( mode != CALIBRATED && !imagePoints.empty() )\n",
    "                runCalibrationAndSave(s, imageSize,  cameraMatrix, distCoeffs, imagePoints, grid_width,\n",
    "                                      release_object);\n",
    "            break;\n",
    "        }\n",
    "        //! [get_input]\n",
    "\n",
    "        imageSize = view.size();  // Format input image.\n",
    "        if( s.flipVertical )    flip( view, view, 0 );\n",
    "\n",
    "        //! [find_pattern]\n",
    "        vector<Point2f> pointBuf;\n",
    "\n",
    "        bool found;\n",
    "\n",
    "        int chessBoardFlags = CALIB_CB_ADAPTIVE_THRESH | CALIB_CB_NORMALIZE_IMAGE;\n",
    "\n",
    "        if(!s.useFisheye) {\n",
    "            // fast check erroneously fails with high distortions like fisheye\n",
    "            chessBoardFlags |= CALIB_CB_FAST_CHECK;\n",
    "        }\n",
    "\n",
    "        switch( s.calibrationPattern ) // Find feature points on the input format\n",
    "        {\n",
    "        case Settings::CHESSBOARD:\n",
    "            found = findChessboardCorners( view, s.boardSize, pointBuf, chessBoardFlags);\n",
    "            break;\n",
    "        case Settings::CIRCLES_GRID:\n",
    "            found = findCirclesGrid( view, s.boardSize, pointBuf );\n",
    "            break;\n",
    "        case Settings::ASYMMETRIC_CIRCLES_GRID:\n",
    "            found = findCirclesGrid( view, s.boardSize, pointBuf, CALIB_CB_ASYMMETRIC_GRID );\n",
    "            break;\n",
    "        default:\n",
    "            found = false;\n",
    "            break;\n",
    "        }\n",
    "        //! [find_pattern]\n",
    "        //! [pattern_found]\n",
    "        if ( found)                // If done with success,\n",
    "        {\n",
    "              // improve the found corners' coordinate accuracy for chessboard\n",
    "                if( s.calibrationPattern == Settings::CHESSBOARD)\n",
    "                {\n",
    "                    Mat viewGray;\n",
    "                    cvtColor(view, viewGray, COLOR_BGR2GRAY);\n",
    "                    cornerSubPix( viewGray, pointBuf, Size(winSize,winSize),\n",
    "                        Size(-1,-1), TermCriteria( TermCriteria::EPS+TermCriteria::COUNT, 30, 0.0001 ));\n",
    "                }\n",
    "\n",
    "                if( mode == CAPTURING &&  // For camera only take new samples after delay time\n",
    "                    (!s.inputCapture.isOpened() || clock() - prevTimestamp > s.delay*1e-3*CLOCKS_PER_SEC) )\n",
    "                {\n",
    "                    imagePoints.push_back(pointBuf);\n",
    "                    prevTimestamp = clock();\n",
    "                    blinkOutput = s.inputCapture.isOpened();\n",
    "                }\n",
    "\n",
    "                // Draw the corners.\n",
    "                drawChessboardCorners( view, s.boardSize, Mat(pointBuf), found );\n",
    "        }\n",
    "        //! [pattern_found]\n",
    "        //----------------------------- Output Text ------------------------------------------------\n",
    "        //! [output_text]\n",
    "        string msg = (mode == CAPTURING) ? \"100/100\" :\n",
    "                      mode == CALIBRATED ? \"Calibrated\" : \"Press 'g' to start\";\n",
    "        int baseLine = 0;\n",
    "        Size textSize = getTextSize(msg, 1, 1, 1, &baseLine);\n",
    "        Point textOrigin(view.cols - 2*textSize.width - 10, view.rows - 2*baseLine - 10);\n",
    "\n",
    "        if( mode == CAPTURING )\n",
    "        {\n",
    "            if(s.showUndistorted)\n",
    "                msg = cv::format( \"%d/%d Undist\", (int)imagePoints.size(), s.nrFrames );\n",
    "            else\n",
    "                msg = cv::format( \"%d/%d\", (int)imagePoints.size(), s.nrFrames );\n",
    "        }\n",
    "\n",
    "        putText( view, msg, textOrigin, 1, 1, mode == CALIBRATED ?  GREEN : RED);\n",
    "\n",
    "        if( blinkOutput )\n",
    "            bitwise_not(view, view);\n",
    "        //! [output_text]\n",
    "        //------------------------- Video capture  output  undistorted ------------------------------\n",
    "        //! [output_undistorted]\n",
    "        if( mode == CALIBRATED && s.showUndistorted )\n",
    "        {\n",
    "            Mat temp = view.clone();\n",
    "            if (s.useFisheye)\n",
    "            {\n",
    "                Mat newCamMat;\n",
    "                fisheye::estimateNewCameraMatrixForUndistortRectify(cameraMatrix, distCoeffs, imageSize,\n",
    "                                                                    Matx33d::eye(), newCamMat, 1);\n",
    "                cv::fisheye::undistortImage(temp, view, cameraMatrix, distCoeffs, newCamMat);\n",
    "            }\n",
    "            else\n",
    "              undistort(temp, view, cameraMatrix, distCoeffs);\n",
    "        }\n",
    "        //! [output_undistorted]\n",
    "        //------------------------------ Show image and check for input commands -------------------\n",
    "        //! [await_input]\n",
    "        imshow(\"Image View\", view);\n",
    "        char key = (char)waitKey(s.inputCapture.isOpened() ? 50 : s.delay);\n",
    "\n",
    "        if( key  == ESC_KEY )\n",
    "            break;\n",
    "\n",
    "        if( key == 'u' && mode == CALIBRATED )\n",
    "           s.showUndistorted = !s.showUndistorted;\n",
    "\n",
    "        if( s.inputCapture.isOpened() && key == 'g' )\n",
    "        {\n",
    "            mode = CAPTURING;\n",
    "            imagePoints.clear();\n",
    "        }\n",
    "        //! [await_input]\n",
    "    }\n",
    "\n",
    "    // -----------------------Show the undistorted image for the image list ------------------------\n",
    "    //! [show_results]\n",
    "    if( s.inputType == Settings::IMAGE_LIST && s.showUndistorted && !cameraMatrix.empty())\n",
    "    {\n",
    "        Mat view, rview, map1, map2;\n",
    "\n",
    "        if (s.useFisheye)\n",
    "        {\n",
    "            Mat newCamMat;\n",
    "            fisheye::estimateNewCameraMatrixForUndistortRectify(cameraMatrix, distCoeffs, imageSize,\n",
    "                                                                Matx33d::eye(), newCamMat, 1);\n",
    "            fisheye::initUndistortRectifyMap(cameraMatrix, distCoeffs, Matx33d::eye(), newCamMat, imageSize,\n",
    "                                             CV_16SC2, map1, map2);\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            initUndistortRectifyMap(\n",
    "                cameraMatrix, distCoeffs, Mat(),\n",
    "                getOptimalNewCameraMatrix(cameraMatrix, distCoeffs, imageSize, 1, imageSize, 0), imageSize,\n",
    "                CV_16SC2, map1, map2);\n",
    "        }\n",
    "\n",
    "        for(size_t i = 0; i < s.imageList.size(); i++ )\n",
    "        {\n",
    "            view = imread(s.imageList[i], IMREAD_COLOR);\n",
    "            if(view.empty())\n",
    "                continue;\n",
    "            remap(view, rview, map1, map2, INTER_LINEAR);\n",
    "            imshow(\"Image View\", rview);\n",
    "            char c = (char)waitKey();\n",
    "            if( c  == ESC_KEY || c == 'q' || c == 'Q' )\n",
    "                break;\n",
    "        }\n",
    "    }\n",
    "    //! [show_results]\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "//! [compute_errors]\n",
    "static double computeReprojectionErrors( const vector<vector<Point3f> >& objectPoints,\n",
    "                                         const vector<vector<Point2f> >& imagePoints,\n",
    "                                         const vector<Mat>& rvecs, const vector<Mat>& tvecs,\n",
    "                                         const Mat& cameraMatrix , const Mat& distCoeffs,\n",
    "                                         vector<float>& perViewErrors, bool fisheye)\n",
    "{\n",
    "    vector<Point2f> imagePoints2;\n",
    "    size_t totalPoints = 0;\n",
    "    double totalErr = 0, err;\n",
    "    perViewErrors.resize(objectPoints.size());\n",
    "\n",
    "    for(size_t i = 0; i < objectPoints.size(); ++i )\n",
    "    {\n",
    "        if (fisheye)\n",
    "        {\n",
    "            fisheye::projectPoints(objectPoints[i], imagePoints2, rvecs[i], tvecs[i], cameraMatrix,\n",
    "                                   distCoeffs);\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            projectPoints(objectPoints[i], rvecs[i], tvecs[i], cameraMatrix, distCoeffs, imagePoints2);\n",
    "        }\n",
    "        err = norm(imagePoints[i], imagePoints2, NORM_L2);\n",
    "\n",
    "        size_t n = objectPoints[i].size();\n",
    "        perViewErrors[i] = (float) std::sqrt(err*err/n);\n",
    "        totalErr        += err*err;\n",
    "        totalPoints     += n;\n",
    "    }\n",
    "\n",
    "    return std::sqrt(totalErr/totalPoints);\n",
    "}\n",
    "//! [compute_errors]\n",
    "//! [board_corners]\n",
    "static void calcBoardCornerPositions(Size boardSize, float squareSize, vector<Point3f>& corners,\n",
    "                                     Settings::Pattern patternType /*= Settings::CHESSBOARD*/)\n",
    "{\n",
    "    corners.clear();\n",
    "\n",
    "    switch(patternType)\n",
    "    {\n",
    "    case Settings::CHESSBOARD:\n",
    "    case Settings::CIRCLES_GRID:\n",
    "        for( int i = 0; i < boardSize.height; ++i )\n",
    "            for( int j = 0; j < boardSize.width; ++j )\n",
    "                corners.push_back(Point3f(j*squareSize, i*squareSize, 0));\n",
    "        break;\n",
    "\n",
    "    case Settings::ASYMMETRIC_CIRCLES_GRID:\n",
    "        for( int i = 0; i < boardSize.height; i++ )\n",
    "            for( int j = 0; j < boardSize.width; j++ )\n",
    "                corners.push_back(Point3f((2*j + i % 2)*squareSize, i*squareSize, 0));\n",
    "        break;\n",
    "    default:\n",
    "        break;\n",
    "    }\n",
    "}\n",
    "//! [board_corners]\n",
    "static bool runCalibration( Settings& s, Size& imageSize, Mat& cameraMatrix, Mat& distCoeffs,\n",
    "                            vector<vector<Point2f> > imagePoints, vector<Mat>& rvecs, vector<Mat>& tvecs,\n",
    "                            vector<float>& reprojErrs,  double& totalAvgErr, vector<Point3f>& newObjPoints,\n",
    "                            float grid_width, bool release_object)\n",
    "{\n",
    "    //! [fixed_aspect]\n",
    "    cameraMatrix = Mat::eye(3, 3, CV_64F);\n",
    "    if( !s.useFisheye && s.flag & CALIB_FIX_ASPECT_RATIO )\n",
    "        cameraMatrix.at<double>(0,0) = s.aspectRatio;\n",
    "    //! [fixed_aspect]\n",
    "    if (s.useFisheye) {\n",
    "        distCoeffs = Mat::zeros(4, 1, CV_64F);\n",
    "    } else {\n",
    "        distCoeffs = Mat::zeros(8, 1, CV_64F);\n",
    "    }\n",
    "\n",
    "    vector<vector<Point3f> > objectPoints(1);\n",
    "    calcBoardCornerPositions(s.boardSize, s.squareSize, objectPoints[0], s.calibrationPattern);\n",
    "    objectPoints[0][s.boardSize.width - 1].x = objectPoints[0][0].x + grid_width;\n",
    "    newObjPoints = objectPoints[0];\n",
    "\n",
    "    objectPoints.resize(imagePoints.size(),objectPoints[0]);\n",
    "\n",
    "    //Find intrinsic and extrinsic camera parameters\n",
    "    double rms;\n",
    "\n",
    "    if (s.useFisheye) {\n",
    "        Mat _rvecs, _tvecs;\n",
    "        rms = fisheye::calibrate(objectPoints, imagePoints, imageSize, cameraMatrix, distCoeffs, _rvecs,\n",
    "                                 _tvecs, s.flag);\n",
    "\n",
    "        rvecs.reserve(_rvecs.rows);\n",
    "        tvecs.reserve(_tvecs.rows);\n",
    "        for(int i = 0; i < int(objectPoints.size()); i++){\n",
    "            rvecs.push_back(_rvecs.row(i));\n",
    "            tvecs.push_back(_tvecs.row(i));\n",
    "        }\n",
    "    } else {\n",
    "        int iFixedPoint = -1;\n",
    "        if (release_object)\n",
    "            iFixedPoint = s.boardSize.width - 1;\n",
    "        rms = calibrateCameraRO(objectPoints, imagePoints, imageSize, iFixedPoint,\n",
    "                                cameraMatrix, distCoeffs, rvecs, tvecs, newObjPoints,\n",
    "                                s.flag | CALIB_USE_LU);\n",
    "    }\n",
    "\n",
    "    if (release_object) {\n",
    "        cout << \"New board corners: \" << endl;\n",
    "        cout << newObjPoints[0] << endl;\n",
    "        cout << newObjPoints[s.boardSize.width - 1] << endl;\n",
    "        cout << newObjPoints[s.boardSize.width * (s.boardSize.height - 1)] << endl;\n",
    "        cout << newObjPoints.back() << endl;\n",
    "    }\n",
    "\n",
    "    cout << \"Re-projection error reported by calibrateCamera: \"<< rms << endl;\n",
    "\n",
    "    bool ok = checkRange(cameraMatrix) && checkRange(distCoeffs);\n",
    "\n",
    "    objectPoints.clear();\n",
    "    objectPoints.resize(imagePoints.size(), newObjPoints);\n",
    "    totalAvgErr = computeReprojectionErrors(objectPoints, imagePoints, rvecs, tvecs, cameraMatrix,\n",
    "                                            distCoeffs, reprojErrs, s.useFisheye);\n",
    "\n",
    "    return ok;\n",
    "}\n",
    "\n",
    "// Print camera parameters to the output file\n",
    "static void saveCameraParams( Settings& s, Size& imageSize, Mat& cameraMatrix, Mat& distCoeffs,\n",
    "                              const vector<Mat>& rvecs, const vector<Mat>& tvecs,\n",
    "                              const vector<float>& reprojErrs, const vector<vector<Point2f> >& imagePoints,\n",
    "                              double totalAvgErr, const vector<Point3f>& newObjPoints )\n",
    "{\n",
    "    FileStorage fs( s.outputFileName, FileStorage::WRITE );\n",
    "\n",
    "    time_t tm;\n",
    "    time( &tm );\n",
    "    struct tm *t2 = localtime( &tm );\n",
    "    char buf[1024];\n",
    "    strftime( buf, sizeof(buf), \"%c\", t2 );\n",
    "\n",
    "    fs << \"calibration_time\" << buf;\n",
    "\n",
    "    if( !rvecs.empty() || !reprojErrs.empty() )\n",
    "        fs << \"nr_of_frames\" << (int)std::max(rvecs.size(), reprojErrs.size());\n",
    "    fs << \"image_width\" << imageSize.width;\n",
    "    fs << \"image_height\" << imageSize.height;\n",
    "    fs << \"board_width\" << s.boardSize.width;\n",
    "    fs << \"board_height\" << s.boardSize.height;\n",
    "    fs << \"square_size\" << s.squareSize;\n",
    "\n",
    "    if( !s.useFisheye && s.flag & CALIB_FIX_ASPECT_RATIO )\n",
    "        fs << \"fix_aspect_ratio\" << s.aspectRatio;\n",
    "\n",
    "    if (s.flag)\n",
    "    {\n",
    "        std::stringstream flagsStringStream;\n",
    "        if (s.useFisheye)\n",
    "        {\n",
    "            flagsStringStream << \"flags:\"\n",
    "                << (s.flag & fisheye::CALIB_FIX_SKEW ? \" +fix_skew\" : \"\")\n",
    "                << (s.flag & fisheye::CALIB_FIX_K1 ? \" +fix_k1\" : \"\")\n",
    "                << (s.flag & fisheye::CALIB_FIX_K2 ? \" +fix_k2\" : \"\")\n",
    "                << (s.flag & fisheye::CALIB_FIX_K3 ? \" +fix_k3\" : \"\")\n",
    "                << (s.flag & fisheye::CALIB_FIX_K4 ? \" +fix_k4\" : \"\")\n",
    "                << (s.flag & fisheye::CALIB_RECOMPUTE_EXTRINSIC ? \" +recompute_extrinsic\" : \"\");\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            flagsStringStream << \"flags:\"\n",
    "                << (s.flag & CALIB_USE_INTRINSIC_GUESS ? \" +use_intrinsic_guess\" : \"\")\n",
    "                << (s.flag & CALIB_FIX_ASPECT_RATIO ? \" +fix_aspectRatio\" : \"\")\n",
    "                << (s.flag & CALIB_FIX_PRINCIPAL_POINT ? \" +fix_principal_point\" : \"\")\n",
    "                << (s.flag & CALIB_ZERO_TANGENT_DIST ? \" +zero_tangent_dist\" : \"\")\n",
    "                << (s.flag & CALIB_FIX_K1 ? \" +fix_k1\" : \"\")\n",
    "                << (s.flag & CALIB_FIX_K2 ? \" +fix_k2\" : \"\")\n",
    "                << (s.flag & CALIB_FIX_K3 ? \" +fix_k3\" : \"\")\n",
    "                << (s.flag & CALIB_FIX_K4 ? \" +fix_k4\" : \"\")\n",
    "                << (s.flag & CALIB_FIX_K5 ? \" +fix_k5\" : \"\");\n",
    "        }\n",
    "        fs.writeComment(flagsStringStream.str());\n",
    "    }\n",
    "\n",
    "    fs << \"flags\" << s.flag;\n",
    "\n",
    "    fs << \"fisheye_model\" << s.useFisheye;\n",
    "\n",
    "    fs << \"camera_matrix\" << cameraMatrix;\n",
    "    fs << \"distortion_coefficients\" << distCoeffs;\n",
    "\n",
    "    fs << \"avg_reprojection_error\" << totalAvgErr;\n",
    "    if (s.writeExtrinsics && !reprojErrs.empty())\n",
    "        fs << \"per_view_reprojection_errors\" << Mat(reprojErrs);\n",
    "\n",
    "    if(s.writeExtrinsics && !rvecs.empty() && !tvecs.empty() )\n",
    "    {\n",
    "        CV_Assert(rvecs[0].type() == tvecs[0].type());\n",
    "        Mat bigmat((int)rvecs.size(), 6, CV_MAKETYPE(rvecs[0].type(), 1));\n",
    "        bool needReshapeR = rvecs[0].depth() != 1 ? true : false;\n",
    "        bool needReshapeT = tvecs[0].depth() != 1 ? true : false;\n",
    "\n",
    "        for( size_t i = 0; i < rvecs.size(); i++ )\n",
    "        {\n",
    "            Mat r = bigmat(Range(int(i), int(i+1)), Range(0,3));\n",
    "            Mat t = bigmat(Range(int(i), int(i+1)), Range(3,6));\n",
    "\n",
    "            if(needReshapeR)\n",
    "                rvecs[i].reshape(1, 1).copyTo(r);\n",
    "            else\n",
    "            {\n",
    "                //*.t() is MatExpr (not Mat) so we can use assignment operator\n",
    "                CV_Assert(rvecs[i].rows == 3 && rvecs[i].cols == 1);\n",
    "                r = rvecs[i].t();\n",
    "            }\n",
    "\n",
    "            if(needReshapeT)\n",
    "                tvecs[i].reshape(1, 1).copyTo(t);\n",
    "            else\n",
    "            {\n",
    "                CV_Assert(tvecs[i].rows == 3 && tvecs[i].cols == 1);\n",
    "                t = tvecs[i].t();\n",
    "            }\n",
    "        }\n",
    "        fs.writeComment(\"a set of 6-tuples (rotation vector + translation vector) for each view\");\n",
    "        fs << \"extrinsic_parameters\" << bigmat;\n",
    "    }\n",
    "\n",
    "    if(s.writePoints && !imagePoints.empty() )\n",
    "    {\n",
    "        Mat imagePtMat((int)imagePoints.size(), (int)imagePoints[0].size(), CV_32FC2);\n",
    "        for( size_t i = 0; i < imagePoints.size(); i++ )\n",
    "        {\n",
    "            Mat r = imagePtMat.row(int(i)).reshape(2, imagePtMat.cols);\n",
    "            Mat imgpti(imagePoints[i]);\n",
    "            imgpti.copyTo(r);\n",
    "        }\n",
    "        fs << \"image_points\" << imagePtMat;\n",
    "    }\n",
    "\n",
    "    if( s.writeGrid && !newObjPoints.empty() )\n",
    "    {\n",
    "        fs << \"grid_points\" << newObjPoints;\n",
    "    }\n",
    "}\n",
    "\n",
    "//! [run_and_save]\n",
    "bool runCalibrationAndSave(Settings& s, Size imageSize, Mat& cameraMatrix, Mat& distCoeffs,\n",
    "                           vector<vector<Point2f> > imagePoints, float grid_width, bool release_object)\n",
    "{\n",
    "    vector<Mat> rvecs, tvecs;\n",
    "    vector<float> reprojErrs;\n",
    "    double totalAvgErr = 0;\n",
    "    vector<Point3f> newObjPoints;\n",
    "\n",
    "    bool ok = runCalibration(s, imageSize, cameraMatrix, distCoeffs, imagePoints, rvecs, tvecs, reprojErrs,\n",
    "                             totalAvgErr, newObjPoints, grid_width, release_object);\n",
    "    cout << (ok ? \"Calibration succeeded\" : \"Calibration failed\")\n",
    "         << \". avg re projection error = \" << totalAvgErr << endl;\n",
    "\n",
    "    if (ok)\n",
    "        saveCameraParams(s, imageSize, cameraMatrix, distCoeffs, rvecs, tvecs, reprojErrs, imagePoints,\n",
    "                         totalAvgErr, newObjPoints);\n",
    "    return ok;\n",
    "}\n",
    "//! [run_and_save]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab exercise\n",
    "\n",
    "1. Write save and read calibration file.\n",
    "2. Use calibration to vdo of chessboard, calibrate it and re-calculate the homography again. Then, do the perspective image from vdo.\n",
    "3. Try to write calibration from scratch (optional)\n",
    "4. Try to use other calibration plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
